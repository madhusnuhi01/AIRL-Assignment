{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dC76vyymBuFZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckx4wE1tNfNR",
        "outputId": "a376f2af-1b7e-4149-84bd-190ede2ff3c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.35.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "from einops import rearrange\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyn60jZ0COl4",
        "outputId": "85f35b74-3a5c-4a98-ab68-d4604769e2ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size=32, patch_size=4, in_chans=3, embed_dim=256):\n",
        "        super().__init__()\n",
        "        assert img_size % patch_size == 0, \"Image size must be divisible by patch size\"\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, attn_dropout=0., proj_dropout=0.):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        self.qkv = nn.Linear(dim, dim * 3)\n",
        "        self.attn_drop = nn.Dropout(attn_dropout)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.reshape(B, N, 3, self.num_heads, C // self.num_heads)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(dim, hidden_dim)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, dim)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4.0, dropout=0., attn_dropout=0.):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = MultiHeadSelfAttention(dim, num_heads, attn_dropout, proj_dropout=dropout)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.mlp = FeedForward(dim, int(dim * mlp_ratio), dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "E4jlfTgFEW8h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "    def __init__(self, *, img_size=32, patch_size=4, in_chans=3, num_classes=10,\n",
        "                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=4.0, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
        "        self.pos_drop = nn.Dropout(p=dropout)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerEncoderBlock(embed_dim, num_heads, mlp_ratio, dropout) for _ in range(depth)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.zeros_(m.bias)\n",
        "            nn.init.ones_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        x = self.patch_embed(x)\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = x + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "        x = self.norm(x)\n",
        "        cls = x[:, 0]\n",
        "        out = self.head(cls)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "msBN9CTaFXLt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import RandAugment\n",
        "\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "def get_dataloaders(batch_size=128, num_workers=2):\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        RandAugment(num_ops=2, magnitude=9),   # added strong augmentation\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ])\n",
        "\n",
        "    train_ds = datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=train_transforms\n",
        "    )\n",
        "    test_ds = datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True, transform=test_transforms\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=num_workers, pin_memory=True\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_ds, batch_size=batch_size, shuffle=False,\n",
        "        num_workers=num_workers, pin_memory=True\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "train_loader, test_loader = get_dataloaders(batch_size=128)\n"
      ],
      "metadata": {
        "id": "ZQSBNA64F4TD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss_meter = 0.0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss_meter += float(loss) * x.size(0)\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += x.size(0)\n",
        "    return loss_meter / total, 100.0 * correct / total\n",
        "\n",
        "def train_one_epoch(model, optimizer, loader, device, scaler, epoch, print_every=100):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(enumerate(loader), total=len(loader))\n",
        "    for i, (x, y) in pbar:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += float(loss.item()) * x.size(0)\n",
        "        if (i + 1) % print_every == 0:\n",
        "            pbar.set_description(f\"Epoch {epoch} iter {i+1} loss {running_loss/((i+1)*x.size(0)):.4f}\")\n",
        "    return running_loss / len(loader.dataset)\n"
      ],
      "metadata": {
        "id": "tBP4Kt6qGHYz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
        "img_size = 32\n",
        "patch_size = 4\n",
        "embed_dim = 256\n",
        "depth = 8\n",
        "num_heads = 8\n",
        "mlp_ratio = 4.0\n",
        "dropout = 0.1\n",
        "\n",
        "epochs = 65\n",
        "batch_size = 128\n",
        "lr = 3e-4\n",
        "weight_decay = 0.05\n",
        "model = ViT(\n",
        "    img_size=img_size,\n",
        "    patch_size=patch_size,\n",
        "    embed_dim=embed_dim,\n",
        "    depth=depth,\n",
        "    num_heads=num_heads,\n",
        "    mlp_ratio=mlp_ratio,\n",
        "    dropout=dropout\n",
        ").to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "steps_per_epoch = len(train_loader)\n",
        "total_steps = steps_per_epoch * epochs\n",
        "\n",
        "scheduler = CosineLRScheduler(\n",
        "    optimizer,\n",
        "    t_initial=total_steps,\n",
        "    lr_min=1e-6,\n",
        "    warmup_t=steps_per_epoch * 5,\n",
        "    warmup_lr_init=1e-6,\n",
        "    t_in_epochs=False,\n",
        ")\n",
        "scaler = GradScaler()\n",
        "best_acc = 0.0\n",
        "global_step = 0\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "\n",
        "\n",
        "        scheduler.step_update(global_step)\n",
        "        global_step += 1\n",
        "\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    val_loss, val_acc = evaluate(model, test_loader, device)\n",
        "    print(f\"Epoch {epoch} TrainLoss {train_loss:.4f} ValLoss {val_loss:.4f} ValAcc {val_acc:.2f}%\")\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_vit_cifar10.pth\")\n",
        "\n",
        "print(\"Best Val Acc: {:.2f}%\".format(best_acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hhJRGQSGVQT",
        "outputId": "355f0b02-a66f-475d-cc36-42c34be18ca0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2199630559.py:36: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-2199630559.py:49: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 TrainLoss 2.1444 ValLoss 1.8939 ValAcc 28.72%\n",
            "Epoch 2 TrainLoss 1.9777 ValLoss 1.8098 ValAcc 34.27%\n",
            "Epoch 3 TrainLoss 1.8091 ValLoss 1.4925 ValAcc 45.97%\n",
            "Epoch 4 TrainLoss 1.6832 ValLoss 1.3190 ValAcc 52.51%\n",
            "Epoch 5 TrainLoss 1.6087 ValLoss 1.2730 ValAcc 53.92%\n",
            "Epoch 6 TrainLoss 1.5529 ValLoss 1.1802 ValAcc 58.77%\n",
            "Epoch 7 TrainLoss 1.5075 ValLoss 1.1403 ValAcc 59.83%\n",
            "Epoch 8 TrainLoss 1.4704 ValLoss 1.1355 ValAcc 59.57%\n",
            "Epoch 9 TrainLoss 1.4408 ValLoss 1.0352 ValAcc 63.48%\n",
            "Epoch 10 TrainLoss 1.4118 ValLoss 1.0197 ValAcc 64.29%\n",
            "Epoch 11 TrainLoss 1.3826 ValLoss 0.9911 ValAcc 65.86%\n",
            "Epoch 12 TrainLoss 1.3577 ValLoss 1.0028 ValAcc 65.40%\n",
            "Epoch 13 TrainLoss 1.3370 ValLoss 0.9262 ValAcc 67.91%\n",
            "Epoch 14 TrainLoss 1.3107 ValLoss 0.9154 ValAcc 68.48%\n",
            "Epoch 15 TrainLoss 1.2856 ValLoss 0.8557 ValAcc 70.95%\n",
            "Epoch 16 TrainLoss 1.2658 ValLoss 0.8575 ValAcc 70.45%\n",
            "Epoch 17 TrainLoss 1.2491 ValLoss 0.8359 ValAcc 71.66%\n",
            "Epoch 18 TrainLoss 1.2274 ValLoss 0.8117 ValAcc 72.64%\n",
            "Epoch 19 TrainLoss 1.2088 ValLoss 0.8004 ValAcc 73.18%\n",
            "Epoch 20 TrainLoss 1.1949 ValLoss 0.7842 ValAcc 73.71%\n",
            "Epoch 21 TrainLoss 1.1805 ValLoss 0.7575 ValAcc 74.70%\n",
            "Epoch 22 TrainLoss 1.1618 ValLoss 0.7419 ValAcc 75.37%\n",
            "Epoch 23 TrainLoss 1.1459 ValLoss 0.7101 ValAcc 76.66%\n",
            "Epoch 24 TrainLoss 1.1366 ValLoss 0.7119 ValAcc 76.82%\n",
            "Epoch 25 TrainLoss 1.1194 ValLoss 0.7075 ValAcc 76.54%\n",
            "Epoch 26 TrainLoss 1.1075 ValLoss 0.6665 ValAcc 77.87%\n",
            "Epoch 27 TrainLoss 1.0952 ValLoss 0.7118 ValAcc 76.28%\n",
            "Epoch 28 TrainLoss 1.0840 ValLoss 0.6556 ValAcc 78.52%\n",
            "Epoch 29 TrainLoss 1.0691 ValLoss 0.6540 ValAcc 78.75%\n",
            "Epoch 30 TrainLoss 1.0532 ValLoss 0.6500 ValAcc 79.03%\n",
            "Epoch 31 TrainLoss 1.0460 ValLoss 0.6376 ValAcc 79.26%\n",
            "Epoch 32 TrainLoss 1.0365 ValLoss 0.6378 ValAcc 79.00%\n",
            "Epoch 33 TrainLoss 1.0209 ValLoss 0.6115 ValAcc 80.36%\n",
            "Epoch 34 TrainLoss 1.0112 ValLoss 0.6004 ValAcc 80.89%\n",
            "Epoch 35 TrainLoss 0.9968 ValLoss 0.5942 ValAcc 81.06%\n",
            "Epoch 36 TrainLoss 0.9886 ValLoss 0.5899 ValAcc 81.46%\n",
            "Epoch 37 TrainLoss 0.9773 ValLoss 0.5662 ValAcc 82.25%\n",
            "Epoch 38 TrainLoss 0.9725 ValLoss 0.5646 ValAcc 82.31%\n",
            "Epoch 39 TrainLoss 0.9625 ValLoss 0.5571 ValAcc 82.56%\n",
            "Epoch 40 TrainLoss 0.9520 ValLoss 0.5502 ValAcc 82.87%\n",
            "Epoch 41 TrainLoss 0.9430 ValLoss 0.5539 ValAcc 82.39%\n",
            "Epoch 42 TrainLoss 0.9318 ValLoss 0.5358 ValAcc 83.18%\n",
            "Epoch 43 TrainLoss 0.9253 ValLoss 0.5367 ValAcc 83.15%\n",
            "Epoch 44 TrainLoss 0.9172 ValLoss 0.5242 ValAcc 83.64%\n",
            "Epoch 45 TrainLoss 0.9111 ValLoss 0.5308 ValAcc 83.65%\n",
            "Epoch 46 TrainLoss 0.9002 ValLoss 0.5375 ValAcc 83.75%\n",
            "Epoch 47 TrainLoss 0.8929 ValLoss 0.5126 ValAcc 84.41%\n",
            "Epoch 48 TrainLoss 0.8892 ValLoss 0.5157 ValAcc 84.23%\n",
            "Epoch 49 TrainLoss 0.8803 ValLoss 0.5245 ValAcc 83.98%\n",
            "Epoch 50 TrainLoss 0.8735 ValLoss 0.5140 ValAcc 84.05%\n",
            "Epoch 51 TrainLoss 0.8684 ValLoss 0.4977 ValAcc 84.91%\n",
            "Epoch 52 TrainLoss 0.8601 ValLoss 0.5028 ValAcc 85.05%\n",
            "Epoch 53 TrainLoss 0.8548 ValLoss 0.4973 ValAcc 85.05%\n",
            "Epoch 54 TrainLoss 0.8527 ValLoss 0.4981 ValAcc 84.95%\n",
            "Epoch 55 TrainLoss 0.8507 ValLoss 0.4964 ValAcc 85.23%\n",
            "Epoch 56 TrainLoss 0.8439 ValLoss 0.4912 ValAcc 85.19%\n",
            "Epoch 57 TrainLoss 0.8374 ValLoss 0.4955 ValAcc 85.30%\n",
            "Epoch 58 TrainLoss 0.8348 ValLoss 0.4914 ValAcc 85.33%\n",
            "Epoch 59 TrainLoss 0.8386 ValLoss 0.4920 ValAcc 85.32%\n",
            "Epoch 60 TrainLoss 0.8284 ValLoss 0.4909 ValAcc 85.53%\n",
            "Epoch 61 TrainLoss 0.8295 ValLoss 0.4849 ValAcc 85.66%\n",
            "Epoch 62 TrainLoss 0.8279 ValLoss 0.4863 ValAcc 85.55%\n",
            "Epoch 63 TrainLoss 0.8314 ValLoss 0.4852 ValAcc 85.65%\n",
            "Epoch 64 TrainLoss 0.8293 ValLoss 0.4880 ValAcc 85.64%\n",
            "Epoch 65 TrainLoss 0.8292 ValLoss 0.4865 ValAcc 85.63%\n",
            "Best Val Acc: 85.66%\n"
          ]
        }
      ]
    }
  ]
}